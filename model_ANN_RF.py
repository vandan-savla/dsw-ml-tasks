# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_XHuvkAWpk8gxR10JxaNbuG98Fmma83d
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from sklearn.ensemble import RandomForestClassifier

#pip install tensorflow

df_history = pd.read_csv('historic.csv')
df_history.head()

df_history['stars'] = df_history['stars'].apply(lambda x: min(x, 5))
df_history['stars'].unique()

class NeuralNetworkModel:
    def __init__(self):
        self.model = Sequential()

    def load(self, filepath):
        self.df = pd.read_csv(filepath)

    def preprocess(self):
        X = self.df.drop(['success_indicator'], axis=1)
        y = self.df['success_indicator']

        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)

        categorical_cols = ['stars','category', 'main_promotion', 'color']
        X_encoded = pd.get_dummies(X, columns=categorical_cols)

        X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)

        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        self.X_train, self.X_test, self.y_train, self.y_test = X_train_scaled, X_test_scaled, y_train, y_test

    def train(self):
        self.model.add(Dense(64, input_dim=self.X_train.shape[1], activation='relu'))
        self.model.add(Dense(32, activation='relu'))
        self.model.add(Dense(len(np.unique(self.y_train)), activation='softmax'))

        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        self.model.fit(self.X_train, self.y_train, epochs=10, batch_size=32, validation_data=(self.X_test, self.y_test))

    def test(self):
        y_pred = np.argmax(self.model.predict(self.X_test), axis=1)

        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted')
        recall = recall_score(self.y_test, y_pred, average='weighted')
        f1 = f1_score(self.y_test, y_pred, average='weighted')
        conf_matrix = confusion_matrix(self.y_test, y_pred)

        print("ANN Metrics ")

        print(f'Accuracy: {accuracy}')
        print(f'Precision: {precision}')
        print(f'Recall: {recall}')
        print(f'F1 Score: {f1}')
        print('Confusion Matrix:\n', conf_matrix)

    def predict(self, new_data):
        new_data_encoded = pd.get_dummies(new_data, columns=['stars','category', 'main_promotion', 'color'])
        new_data_scaled = StandardScaler().fit_transform(new_data_encoded)
        return np.argmax(self.model.predict(new_data_scaled), axis=1)


class RandomForestModel:
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)

    def load(self, filepath):
        self.df = pd.read_csv(filepath)

    def preprocess(self):
        X = self.df.drop(['success_indicator'], axis=1)
        y = self.df['success_indicator']

        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)

        categorical_cols = ['stars','category', 'main_promotion', 'color']

        X_encoded = pd.get_dummies(X, columns=categorical_cols)

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)

    def train(self):
        self.model.fit(self.X_train, self.y_train)

    def test(self):
        y_pred = self.model.predict(self.X_test)

        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted')
        recall = recall_score(self.y_test, y_pred, average='weighted')
        f1 = f1_score(self.y_test, y_pred, average='weighted')
        conf_matrix = confusion_matrix(self.y_test, y_pred)

        print("Random Forest Metrics ")

        print(f'Accuracy: {accuracy}')
        print(f'Precision: {precision}')
        print(f'Recall: {recall}')
        print(f'F1 Score: {f1}')
        print('Confusion Matrix:\n', conf_matrix)

    def predict(self, new_data):
        new_data_encoded = pd.get_dummies(new_data, columns=['stars','category', 'main_promotion', 'color'])
        return self.model.predict(new_data_encoded)


# Example for Neural Network
nn_model = NeuralNetworkModel()
nn_model.load('historic.csv')
nn_model.preprocess()
nn_model.train()
nn_model.test()

# Example for Random Forest
rf_model = RandomForestModel()
rf_model.load('historic.csv')
rf_model.preprocess()
rf_model.train()
rf_model.test()

"""We Found that the accuracy of ANN is greater than Random Forest Classifier

### On real Data with prediction_input.csv
"""



df_p = pd.read_csv('prediction_input.csv')
print(df_p.info())

